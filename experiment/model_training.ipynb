{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, lower, regexp_replace, trim\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover, Word2Vec, StringIndexer, IndexToString\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from util import cleanser, lower_case, stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version =  3.3.2\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Music Genre Prediction\")\\\n",
    "    .config(\"spark.driver.memory\", \"4g\")\\\n",
    "    .config(\"spark.executor.memory\", \"4g\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "print( \"Spark version = \", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Load mendeley dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mendeley_music_df = spark.read.option(\"header\", True).csv(\"../data/mendeley_dataset.csv\")\n",
    "\n",
    "mendeley_music_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mendeley_music_selected_df = mendeley_music_df.select(\"artist_name\", \"track_name\", \"release_date\", \"genre\", \"lyrics\")\n",
    "\n",
    "mendeley_music_selected_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mendeley_music_selected_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mendeley_music_selected_df.groupBy(\"genre\").count().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Load merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-----+--------------------+\n",
      "|         artist_name|          track_name|release_date|genre|              lyrics|\n",
      "+--------------------+--------------------+------------+-----+--------------------+\n",
      "|              mukesh|mohabbat bhi jhoothi|        1950|  pop|hold time feel br...|\n",
      "|       frankie laine|           i believe|        1950|  pop|believe drop rain...|\n",
      "|         johnnie ray|                 cry|        1950|  pop|sweetheart send l...|\n",
      "|         pérez prado|            patricia|        1950|  pop|kiss lips want st...|\n",
      "|giorgos papadopoulos|  apopse eida oneiro|        1950|  pop|till darling till...|\n",
      "+--------------------+--------------------+------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df = spark.read.option(\"header\", True).csv(\"../Merged_dataset.csv\")\n",
    "\n",
    "merged_df = merged_df.select(\"artist_name\", \"track_name\", \"release_date\", \"genre\", \"lyrics\")\n",
    "\n",
    "merged_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- lyrics: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|  genre|count|\n",
      "+-------+-----+\n",
      "|    pop| 7042|\n",
      "|country| 5445|\n",
      "|  blues| 4604|\n",
      "|   jazz| 3845|\n",
      "|   rock| 4034|\n",
      "| reggae| 2498|\n",
      "|hip hop|  904|\n",
      "|  retro|  187|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df.groupBy(\"genre\").count().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing - Without Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Remove punctuation symbols and double spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_pattern = \"[^\\w\\s]\"\n",
    "space_pattern = \"\\s{2,}\"\n",
    "\n",
    "mendeley_music_selected_df = mendeley_music_selected_df.withColumn(\"lyrics_cleaned\", regexp_replace(\"lyrics\", punc_pattern, \"\"))\n",
    "mendeley_music_selected_df = mendeley_music_selected_df.withColumn(\"lyrics_cleaned\", trim(regexp_replace(\"lyrics_cleaned\", space_pattern, \" \")))\n",
    "\n",
    "mendeley_music_selected_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mendeley_music_selected_df.filter(col(\"lyrics_cleaned\").rlike(r'[^\\w\\s]')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Convert the text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mendeley_music_selected_df = mendeley_music_selected_df.withColumn(\"lyrics_lower\", lower(col(\"lyrics_cleaned\")))\n",
    "\n",
    "mendeley_music_selected_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Tokenize the lyrics column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"lyrics_lower\", outputCol=\"tokens\")\n",
    "mendeley_music_selected_df = tokenizer.transform(mendeley_music_selected_df)\n",
    "\n",
    "mendeley_music_selected_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Remove stop words from the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_wo_sw\")\n",
    "mendeley_music_selected_df = remover.transform(mendeley_music_selected_df)\n",
    "\n",
    "mendeley_music_selected_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Stem the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_ = SnowballStemmer(language='english')\n",
    "stemming_udf = udf(lambda tokens: [stemmer_.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "mendeley_music_selected_df = mendeley_music_selected_df.withColumn(\"words_stemmed\", stemming_udf(col(\"tokens_wo_sw\")))\n",
    "\n",
    "mendeley_music_selected_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Word2Vec model\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=5, inputCol=\"words_stemmed\", outputCol=\"features\")\n",
    "word2Vec_model = word2Vec.fit(mendeley_music_selected_df)\n",
    "\n",
    "# Extract the features\n",
    "mendeley_music_selected_df = word2Vec_model.transform(mendeley_music_selected_df)\n",
    "\n",
    "\n",
    "mendeley_music_selected_df.show(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the genre column\n",
    "indexer = StringIndexer(inputCol=\"genre\", outputCol=\"label\")\n",
    "mendeley_music_selected_df = indexer.fit(mendeley_music_selected_df).transform(mendeley_music_selected_df)\n",
    "\n",
    "mendeley_music_selected_df.show(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train, test = mendeley_music_selected_df.randomSplit([0.8, 0.2], seed=239375)\n",
    "\n",
    "print(\"training set shape: ({}, {})\".format(train.count(), len(train.columns)))\n",
    "print(\"test set shape: ({}, {})\".format(test.count(), len(test.columns)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10, regParam=0.01)\n",
    "lr_model = lr.fit(train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_train_pred = lr_model.transform(train)\n",
    "y_test_pred = lr_model.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "train_accuracy = evaluator.evaluate(y_train_pred)\n",
    "test_accuracy = evaluator.evaluate(y_test_pred)\n",
    "\n",
    "print(\"Training Set Accuracy = {:.4f}\".format(train_accuracy))\n",
    "print(\"Test Set Accuracy = {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest model\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", maxDepth=30, numTrees=10, maxBins=128)\n",
    "rf_model = rf.fit(train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_train_pred = rf_model.transform(train)\n",
    "y_test_pred = rf_model.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "train_accuracy = evaluator.evaluate(y_train_pred)\n",
    "test_accuracy = evaluator.evaluate(y_test_pred)\n",
    "\n",
    "print(\"Training Set Accuracy = {:.4f}\".format(train_accuracy))\n",
    "print(\"Test Set Accuracy = {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing - With Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1 - Cleanser\n",
    "cleanser = cleanser.Cleanser(inputCol=\"lyrics\", outputCol=\"lyrics_cleaned\")\n",
    "\n",
    "# Stage 2 - Lower case\n",
    "lower_ = lower_case.Lower(inputCol=\"lyrics_cleaned\", outputCol=\"lyrics_lower\")\n",
    "\n",
    "# Stage 3 - Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"lyrics_lower\", outputCol=\"tokens\")\n",
    "\n",
    "# Stage 4 - Stop words remover\n",
    "sw_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_wo_sw\")\n",
    "\n",
    "# Stage 5 - Stemmer\n",
    "stemmer = stemmer.Stemmer(inputCol=\"tokens_wo_sw\", outputCol=\"words_stemmed\")\n",
    "\n",
    "# Stage 6 - Word2Vec\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=5, inputCol=\"words_stemmed\", outputCol=\"features\")\n",
    "\n",
    "# Stage 7 - StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"genre\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[cleanser,\n",
    "                            lower_,\n",
    "                            tokenizer,\n",
    "                            sw_remover,\n",
    "                            stemmer,\n",
    "                            word2Vec,\n",
    "                            indexer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data to pipeline\n",
    "data_prep_model = pipeline.fit(mendeley_music_selected_df)\n",
    "\n",
    "preprocessed_df = data_prep_model.transform(mendeley_music_selected_df)\n",
    "\n",
    "preprocessed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data prep model\n",
    "data_prep_model.save(\"../model/data_prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train, test = preprocessed_df.randomSplit([0.8, 0.2], seed=239375)\n",
    "\n",
    "print(\"training set shape: ({}, {})\".format(train.count(), len(train.columns)))\n",
    "print(\"test set shape: ({}, {})\".format(test.count(), len(test.columns)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection and Hyperparameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 1]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "lr_cv_model = crossval.fit(train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_train_pred = lr_cv_model.transform(train)\n",
    "y_test_pred = lr_cv_model.transform(test)\n",
    "\n",
    "train_accuracy = evaluator.evaluate(y_train_pred)\n",
    "test_accuracy = evaluator.evaluate(y_test_pred)\n",
    "\n",
    "print(\"Training Set Accuracy = {:.4f}\".format(train_accuracy))\n",
    "print(\"Test Set Accuracy = {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save logistic regression model\n",
    "lr_cv_model.write().overwrite().save(\"../model/logistic_regression/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [3, 5, 7, 10]) \\\n",
    "    .addGrid(rf.maxDepth, [4, 8, 10]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=rf,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "rf_cv_model = crossval.fit(train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_train_pred = rf_cv_model.transform(train)\n",
    "y_test_pred = rf_cv_model.transform(test)\n",
    "\n",
    "train_accuracy = evaluator.evaluate(y_train_pred)\n",
    "test_accuracy = evaluator.evaluate(y_test_pred)\n",
    "\n",
    "print(\"Training Set Accuracy = {:.4f}\".format(train_accuracy))\n",
    "print(\"Test Set Accuracy = {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the random forest model\n",
    "rf_cv_model.write().overwrite().save(\"../model/random_forest/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict 8 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|         artist_name|          track_name|release_date|genre|              lyrics|      lyrics_cleaned|        lyrics_lower|              tokens|        tokens_wo_sw|       words_stemmed|            features|\n",
      "+--------------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|              mukesh|mohabbat bhi jhoothi|        1950|  pop|hold time feel br...|hold time feel br...|hold time feel br...|[hold, time, feel...|[hold, time, feel...|[hold, time, feel...|[0.07735481149713...|\n",
      "|       frankie laine|           i believe|        1950|  pop|believe drop rain...|believe drop rain...|believe drop rain...|[believe, drop, r...|[believe, drop, r...|[believ, drop, ra...|[0.07330363547468...|\n",
      "|         johnnie ray|                 cry|        1950|  pop|sweetheart send l...|sweetheart send l...|sweetheart send l...|[sweetheart, send...|[sweetheart, send...|[sweetheart, send...|[0.06035575876012...|\n",
      "|         pérez prado|            patricia|        1950|  pop|kiss lips want st...|kiss lips want st...|kiss lips want st...|[kiss, lips, want...|[kiss, lips, want...|[kiss, lip, want,...|[0.04002149686803...|\n",
      "|giorgos papadopoulos|  apopse eida oneiro|        1950|  pop|till darling till...|till darling till...|till darling till...|[till, darling, t...|[till, darling, t...|[till, darl, till...|[0.08630982221802...|\n",
      "+--------------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stage 1 - Cleanser\n",
    "cleanser = cleanser.Cleanser(inputCol=\"lyrics\", outputCol=\"lyrics_cleaned\")\n",
    "\n",
    "# Stage 2 - Lower case\n",
    "lower_ = lower_case.Lower(inputCol=\"lyrics_cleaned\", outputCol=\"lyrics_lower\")\n",
    "\n",
    "# Stage 3 - Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"lyrics_lower\", outputCol=\"tokens\")\n",
    "\n",
    "# Stage 4 - Stop words remover\n",
    "sw_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_wo_sw\")\n",
    "\n",
    "# Stage 5 - Stemmer\n",
    "stemmer = stemmer.Stemmer(inputCol=\"tokens_wo_sw\", outputCol=\"words_stemmed\")\n",
    "\n",
    "# Stage 6 - Word2Vec\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=5, inputCol=\"words_stemmed\", outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[cleanser,\n",
    "                            lower_,\n",
    "                            tokenizer,\n",
    "                            sw_remover,\n",
    "                            stemmer,\n",
    "                            word2Vec\n",
    "                            ])\n",
    "\n",
    "# Fit and transform the data to pipeline\n",
    "data_prep_model = pipeline.fit(merged_df)\n",
    "preprocessed_df = data_prep_model.transform(merged_df)\n",
    "\n",
    "# Save the data prep model\n",
    "data_prep_model.write().overwrite().save(\"../model/8-classes/data_prep/\")\n",
    "\n",
    "preprocessed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|  artist_name|          track_name|release_date|genre|              lyrics|      lyrics_cleaned|        lyrics_lower|              tokens|        tokens_wo_sw|       words_stemmed|            features|label|\n",
      "+-------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|       mukesh|mohabbat bhi jhoothi|        1950|  pop|hold time feel br...|hold time feel br...|hold time feel br...|[hold, time, feel...|[hold, time, feel...|[hold, time, feel...|[0.07735481149713...|  0.0|\n",
      "|frankie laine|           i believe|        1950|  pop|believe drop rain...|believe drop rain...|believe drop rain...|[believe, drop, r...|[believe, drop, r...|[believ, drop, ra...|[0.07330363547468...|  0.0|\n",
      "|  johnnie ray|                 cry|        1950|  pop|sweetheart send l...|sweetheart send l...|sweetheart send l...|[sweetheart, send...|[sweetheart, send...|[sweetheart, send...|[0.06035575876012...|  0.0|\n",
      "+-------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Label encode the genre column\n",
    "indexer = StringIndexer(inputCol=\"genre\", outputCol=\"label\")\n",
    "preprocessed_df = indexer.fit(preprocessed_df).transform(preprocessed_df)\n",
    "\n",
    "indexer.write().overwrite().save(\"../model/8-classes/string_indexer/\")\n",
    "\n",
    "preprocessed_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# create an IndexToString transformer to convert the index back to the original string value\n",
    "converter = IndexToString(inputCol=\"label\", outputCol=\"genre_new\")\n",
    "preprocessed_df = converter.transform(preprocessed_df)\n",
    "\n",
    "converter.write().overwrite().save(\"../model/8-classes/index_converter/\")\n",
    "\n",
    "preprocessed_df.show(3)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape: (22835, 12)\n",
      "test set shape: (5724, 12)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train, test = preprocessed_df.randomSplit([0.8, 0.2], seed=239375)\n",
    "\n",
    "print(\"training set shape: ({}, {})\".format(train.count(), len(train.columns)))\n",
    "print(\"test set shape: ({}, {})\".format(test.count(), len(test.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy = 0.3529\n",
      "Test Set Accuracy = 0.3368\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 1, 10]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "lr_cv_model = crossval.fit(train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_train_pred = lr_cv_model.transform(train)\n",
    "y_test_pred = lr_cv_model.transform(test)\n",
    "\n",
    "train_accuracy = evaluator.evaluate(y_train_pred)\n",
    "test_accuracy = evaluator.evaluate(y_test_pred)\n",
    "\n",
    "print(\"Training Set Accuracy = {:.4f}\".format(train_accuracy))\n",
    "print(\"Test Set Accuracy = {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save logistic regression model\n",
    "lr_cv_model.write().overwrite().save(\"../model/8-classes/logistic_regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|         artist_name|          track_name|release_date|genre|              lyrics|      lyrics_cleaned|        lyrics_lower|              tokens|        tokens_wo_sw|       words_stemmed|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|\"\"\"weird al\"\" yan...|(this song's just...|        1988|  pop|song word long so...|song word long so...|song word long so...|[song, word, long...|[song, word, long...|[song, word, long...|[0.04522284265193...|  0.0|[1.26023733149032...|[0.21667971468847...|       1.0|\n",
      "|\"\"\"weird al\"\" yan...|   addicted to spuds|        1986|  pop|potato skin potat...|potato skin potat...|potato skin potat...|[potato, skin, po...|[potato, skin, po...|[potato, skin, po...|[0.12958343531317...|  0.0|[1.77460113208928...|[0.40440059609096...|       0.0|\n",
      "|\"\"\"weird al\"\" yan...|christmas at grou...|        1986|  pop|christmas grind z...|christmas grind z...|christmas grind z...|[christmas, grind...|[christmas, grind...|[christma, grind,...|[0.01988405855032...|  0.0|[1.06986970982751...|[0.26883454224378...|       0.0|\n",
      "+--------------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_pred = lr_cv_model.transform(preprocessed_df)\n",
    "\n",
    "y_all_pred_df = y_all_pred.toPandas()\n",
    "\n",
    "y_all_pred_df.to_csv(\"../data/lr_pred_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [3, 5, 7, 10]) \\\n",
    "    .addGrid(rf.maxDepth, [4, 8, 10]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=rf,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "rf_cv_model = crossval.fit(train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_train_pred = rf_cv_model.transform(train)\n",
    "y_test_pred = rf_cv_model.transform(test)\n",
    "\n",
    "train_accuracy = evaluator.evaluate(y_train_pred)\n",
    "test_accuracy = evaluator.evaluate(y_test_pred)\n",
    "\n",
    "print(\"Training Set Accuracy = {:.4f}\".format(train_accuracy))\n",
    "print(\"Test Set Accuracy = {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the random forest model\n",
    "rf_cv_model.write().overwrite().save(\"../model/8-classes/random_forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
