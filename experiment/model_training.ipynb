{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, lower, regexp_replace, trim\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover, Word2Vec, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from util import cleanser, lower_case, stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version =  3.3.2\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Music Genre Prediction\")\\\n",
    "    .config(\"spark.driver.memory\", \"4g\")\\\n",
    "    .config(\"spark.executor.memory\", \"4g\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "print( \"Spark version = \", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+------------+-----+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+--------------------+-------------------+-------------------+----------+---+\n",
      "|_c0|         artist_name|          track_name|release_date|genre|              lyrics|len|              dating|            violence|          world/life|          night/time|  shake the audience|       family/gospel|            romantic|       communication|             obscene|               music|     movement/places|light/visual perceptions|    family/spiritual|          like/girls|             sadness|            feelings|       danceability|           loudness|       acousticness|    instrumentalness|            valence|             energy|     topic|age|\n",
      "+---+--------------------+--------------------+------------+-----+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+--------------------+-------------------+-------------------+----------+---+\n",
      "|  0|              mukesh|mohabbat bhi jhoothi|        1950|  pop|hold time feel br...| 95|0.000598086126288938| 0.06374612761149936|0.000598086156871...|0.000598086185173...|0.000598086127449...| 0.04885701521695907|  0.0171043388602836|  0.2637508813174463|0.000598086161324...| 0.03928836592552566|0.000598086192264...|    0.000598086138027...|0.000598086126136...|0.000598086179608...|   0.380298895230333| 0.11717545142309628|0.35773854651792486|0.45411891392969767| 0.9979919658553876|  0.9018218623481781|0.33944765045342123|0.13711018802589228|   sadness|1.0|\n",
      "|  4|       frankie laine|           i believe|        1950|  pop|believe drop rain...| 51|  0.0355371338259024| 0.09677674227829695| 0.44343517381864045|0.001283697113893...|0.001283697054027...| 0.02700747737752981|0.001283697149879...|0.001283697122283...|0.001283697114412...| 0.11803384116823598|0.001283697092589732|      0.2126810671851602| 0.05112419901776462|0.001283697056361...|0.001283697130026...|0.001283697175168...|0.33174482833315283|   0.64753993282568| 0.9548192317462166|1.528340080971659...| 0.3250206100577081| 0.2632402533492537|world/life|1.0|\n",
      "|  6|         johnnie ray|                 cry|        1950|  pop|sweetheart send l...| 24|0.002770083112964...|0.002770083216950...|0.002770083338284...|0.002770083310265701|0.002770083105133...| 0.00277008314953857| 0.15856446565813143| 0.25066790992061416|0.002770083254843025|  0.3237940521915833|0.002770083466243...|    0.002770083321430...|0.002770083291967...|0.002770083513581458|0.002770083190828636| 0.22542232330826406|0.45629806130185213|  0.585288311155552| 0.8403612855032989|                 0.0|0.35181368507831823|0.13911225255483453|     music|1.0|\n",
      "| 10|         pérez prado|            patricia|        1950|  pop|kiss lips want st...| 54| 0.04824912378369902|0.001547987647649...|0.001547987736006...|0.001547987822572...|0.021500355476212204|0.001547987658152495| 0.41153582463430627|0.001547987749586...|0.001547987713396...|0.001547987673344...|  0.1292497848687442|    0.001547987722954...|0.001547987649057...|  0.0811317603482602| 0.22588948422032734|0.001547987619397...| 0.6869923101917037| 0.7444042765941081|0.08393482322773417| 0.19939271255060728| 0.7753503709810387| 0.7437357402953926|  romantic|1.0|\n",
      "| 12|giorgos papadopoulos|  apopse eida oneiro|        1950|  pop|till darling till...| 48|0.001349527698357...|0.001349527710717...|  0.4177722727138843|0.001349527769804...|0.001349527675244...|0.001349527706827...| 0.46343009486128023|0.001349527805997...|0.001349527691256...|0.001349527677136...|0.001349527712799...|    0.001349527797172...|0.029754565101290716|0.001349527684528...| 0.06880015162837107|0.001349527670906...| 0.2916711794649627| 0.6464887316360279| 0.9759035902646489|0.000245951417004...|  0.597073371805441| 0.3943754799949707|  romantic|1.0|\n",
      "+---+--------------------+--------------------+------------+-----+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+--------------------+-------------------+-------------------+----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mendeley_music_df = spark.read.option(\"header\", True).csv(\"../data/mendeley_dataset.csv\")\n",
    "\n",
    "mendeley_music_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-----+--------------------+\n",
      "|         artist_name|          track_name|release_date|genre|              lyrics|\n",
      "+--------------------+--------------------+------------+-----+--------------------+\n",
      "|              mukesh|mohabbat bhi jhoothi|        1950|  pop|hold time feel br...|\n",
      "|       frankie laine|           i believe|        1950|  pop|believe drop rain...|\n",
      "|         johnnie ray|                 cry|        1950|  pop|sweetheart send l...|\n",
      "|         pérez prado|            patricia|        1950|  pop|kiss lips want st...|\n",
      "|giorgos papadopoulos|  apopse eida oneiro|        1950|  pop|till darling till...|\n",
      "+--------------------+--------------------+------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mendeley_music_selected_df = mendeley_music_df.select(\"artist_name\", \"track_name\", \"release_date\", \"genre\", \"lyrics\")\n",
    "\n",
    "mendeley_music_selected_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- lyrics: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mendeley_music_selected_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|  genre|count|\n",
      "+-------+-----+\n",
      "|    pop| 7042|\n",
      "|country| 5445|\n",
      "|  blues| 4604|\n",
      "|   jazz| 3845|\n",
      "| reggae| 2498|\n",
      "|   rock| 4034|\n",
      "|hip hop|  904|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mendeley_music_selected_df.groupBy(\"genre\").count().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing - Without Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Remove punctuation symbols and double spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_pattern = \"[^\\w\\s]\"\n",
    "space_pattern = \"\\s{2,}\"\n",
    "\n",
    "mendeley_music_selected_df = mendeley_music_selected_df.withColumn(\"lyrics_cleaned\", regexp_replace(\"lyrics\", punc_pattern, \"\"))\n",
    "mendeley_music_selected_df = mendeley_music_selected_df.withColumn(\"lyrics_cleaned\", trim(regexp_replace(\"lyrics_cleaned\", space_pattern, \" \")))\n",
    "\n",
    "mendeley_music_selected_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mendeley_music_selected_df.filter(col(\"lyrics_cleaned\").rlike(r'[^\\w\\s]')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Convert the text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mendeley_music_selected_df = mendeley_music_selected_df.withColumn(\"lyrics_lower\", lower(col(\"lyrics_cleaned\")))\n",
    "\n",
    "mendeley_music_selected_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Tokenize the lyrics column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"lyrics_lower\", outputCol=\"tokens\")\n",
    "mendeley_music_selected_df = tokenizer.transform(mendeley_music_selected_df)\n",
    "\n",
    "mendeley_music_selected_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Remove stop words from the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_wo_sw\")\n",
    "mendeley_music_selected_df = remover.transform(mendeley_music_selected_df)\n",
    "\n",
    "mendeley_music_selected_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Stem the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_ = SnowballStemmer(language='english')\n",
    "stemming_udf = udf(lambda tokens: [stemmer_.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "mendeley_music_selected_df = mendeley_music_selected_df.withColumn(\"words_stemmed\", stemming_udf(col(\"tokens_wo_sw\")))\n",
    "\n",
    "mendeley_music_selected_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Word2Vec model\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=5, inputCol=\"words_stemmed\", outputCol=\"features\")\n",
    "word2Vec_model = word2Vec.fit(mendeley_music_selected_df)\n",
    "\n",
    "# Extract the features\n",
    "mendeley_music_selected_df = word2Vec_model.transform(mendeley_music_selected_df)\n",
    "\n",
    "\n",
    "mendeley_music_selected_df.show(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the genre column\n",
    "indexer = StringIndexer(inputCol=\"genre\", outputCol=\"label\")\n",
    "mendeley_music_selected_df = indexer.fit(mendeley_music_selected_df).transform(mendeley_music_selected_df)\n",
    "\n",
    "mendeley_music_selected_df.show(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train, test = mendeley_music_selected_df.randomSplit([0.8, 0.2], seed=239375)\n",
    "\n",
    "print(\"training set shape: ({}, {})\".format(train.count(), len(train.columns)))\n",
    "print(\"test set shape: ({}, {})\".format(test.count(), len(test.columns)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10, regParam=0.01)\n",
    "lr_model = lr.fit(train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_train_pred = lr_model.transform(train)\n",
    "y_test_pred = lr_model.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "train_accuracy = evaluator.evaluate(y_train_pred)\n",
    "test_accuracy = evaluator.evaluate(y_test_pred)\n",
    "\n",
    "print(\"Training Set Accuracy = {:.4f}\".format(train_accuracy))\n",
    "print(\"Test Set Accuracy = {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest model\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", maxDepth=30, numTrees=10, maxBins=128)\n",
    "rf_model = rf.fit(train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_train_pred = rf_model.transform(train)\n",
    "y_test_pred = rf_model.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "train_accuracy = evaluator.evaluate(y_train_pred)\n",
    "test_accuracy = evaluator.evaluate(y_test_pred)\n",
    "\n",
    "print(\"Training Set Accuracy = {:.4f}\".format(train_accuracy))\n",
    "print(\"Test Set Accuracy = {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing - With Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1 - Cleanser\n",
    "cleanser = cleanser.Cleanser(inputCol=\"lyrics\", outputCol=\"lyrics_cleaned\")\n",
    "\n",
    "# Stage 2 - Lower case\n",
    "lower_ = lower_case.Lower(inputCol=\"lyrics_cleaned\", outputCol=\"lyrics_lower\")\n",
    "\n",
    "# Stage 3 - Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"lyrics_lower\", outputCol=\"tokens\")\n",
    "\n",
    "# Stage 4 - Stop words remover\n",
    "sw_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_wo_sw\")\n",
    "\n",
    "# Stage 5 - Stemmer\n",
    "stemmer = stemmer.Stemmer(inputCol=\"tokens_wo_sw\", outputCol=\"words_stemmed\")\n",
    "\n",
    "# Stage 6 - Word2Vec\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=5, inputCol=\"words_stemmed\", outputCol=\"features\")\n",
    "\n",
    "# Stage 7 - StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"genre\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[cleanser,\n",
    "                            lower_,\n",
    "                            tokenizer,\n",
    "                            sw_remover,\n",
    "                            stemmer,\n",
    "                            word2Vec,\n",
    "                            indexer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|         artist_name|          track_name|release_date|genre|              lyrics|      lyrics_cleaned|        lyrics_lower|              tokens|        tokens_wo_sw|       words_stemmed|            features|label|\n",
      "+--------------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|              mukesh|mohabbat bhi jhoothi|        1950|  pop|hold time feel br...|hold time feel br...|hold time feel br...|[hold, time, feel...|[hold, time, feel...|[hold, time, feel...|[0.04448236527815...|  0.0|\n",
      "|       frankie laine|           i believe|        1950|  pop|believe drop rain...|believe drop rain...|believe drop rain...|[believe, drop, r...|[believe, drop, r...|[believ, drop, ra...|[0.06146253434046...|  0.0|\n",
      "|         johnnie ray|                 cry|        1950|  pop|sweetheart send l...|sweetheart send l...|sweetheart send l...|[sweetheart, send...|[sweetheart, send...|[sweetheart, send...|[-0.1101356239523...|  0.0|\n",
      "|         pérez prado|            patricia|        1950|  pop|kiss lips want st...|kiss lips want st...|kiss lips want st...|[kiss, lips, want...|[kiss, lips, want...|[kiss, lip, want,...|[-0.0576698493257...|  0.0|\n",
      "|giorgos papadopoulos|  apopse eida oneiro|        1950|  pop|till darling till...|till darling till...|till darling till...|[till, darling, t...|[till, darling, t...|[till, darl, till...|[-0.0140430459493...|  0.0|\n",
      "+--------------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform the data to pipeline\n",
    "data_prep_model = pipeline.fit(mendeley_music_selected_df)\n",
    "\n",
    "preprocessed_df = data_prep_model.transform(mendeley_music_selected_df)\n",
    "\n",
    "preprocessed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data prep model\n",
    "data_prep_model.save(\"../model/data_prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape: (22696, 12)\n",
      "test set shape: (5676, 12)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train, test = preprocessed_df.randomSplit([0.8, 0.2], seed=239375)\n",
    "\n",
    "print(\"training set shape: ({}, {})\".format(train.count(), len(train.columns)))\n",
    "print(\"test set shape: ({}, {})\".format(test.count(), len(test.columns)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection and Hyperparameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy = 0.3609\n",
      "Test Set Accuracy = 0.3465\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 1]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "lr_cv_model = crossval.fit(train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_train_pred = lr_cv_model.transform(train)\n",
    "y_test_pred = lr_cv_model.transform(test)\n",
    "\n",
    "train_accuracy = evaluator.evaluate(y_train_pred)\n",
    "test_accuracy = evaluator.evaluate(y_test_pred)\n",
    "\n",
    "print(\"Training Set Accuracy = {:.4f}\".format(train_accuracy))\n",
    "print(\"Test Set Accuracy = {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|         artist_name|          track_name|release_date|genre|              lyrics|      lyrics_cleaned|        lyrics_lower|              tokens|        tokens_wo_sw|       words_stemmed|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|\"\"\"weird al\"\" yan...|(this song's just...|        1988|  pop|song word long so...|song word long so...|song word long so...|[song, word, long...|[song, word, long...|[song, word, long...|[0.10238660435887...|  0.0|[0.69263167391290...|[0.21383980190181...|       0.0|\n",
      "|\"\"\"weird al\"\" yan...|   addicted to spuds|        1986|  pop|potato skin potat...|potato skin potat...|potato skin potat...|[potato, skin, po...|[potato, skin, po...|[potato, skin, po...|[0.10056270723168...|  0.0|[0.86890308642193...|[0.28631796880293...|       0.0|\n",
      "|\"\"\"weird al\"\" yan...|christmas at grou...|        1986|  pop|christmas grind z...|christmas grind z...|christmas grind z...|[christmas, grind...|[christmas, grind...|[christma, grind,...|[-0.0154012615865...|  0.0|[0.68821119971537...|[0.24067338315283...|       0.0|\n",
      "+--------------------+--------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save logistic regression model\n",
    "lr_cv_model.write().overwrite().save(\"../model/logistic_regression/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy = 0.4320\n",
      "Test Set Accuracy = 0.3095\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [3, 5, 7, 10]) \\\n",
    "    .addGrid(rf.maxDepth, [4, 8, 10]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=rf,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "rf_cv_model = crossval.fit(train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_train_pred = rf_cv_model.transform(train)\n",
    "y_test_pred = rf_cv_model.transform(test)\n",
    "\n",
    "train_accuracy = evaluator.evaluate(y_train_pred)\n",
    "test_accuracy = evaluator.evaluate(y_test_pred)\n",
    "\n",
    "print(\"Training Set Accuracy = {:.4f}\".format(train_accuracy))\n",
    "print(\"Test Set Accuracy = {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the random forest model\n",
    "rf_cv_model.write().overwrite().save(\"../model/random_forest/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
